[['125.00.00.5625', 1], ['45.00.00.375', 1], ['150.00.00.75', 1], ['45.00.00.375', 4], ['125.00.00.5625', 4], ['150.00.00.75', 4]]
id :  150.00.00.75 count :  2
id :  45.00.00.375 count :  15
id :  125.00.00.5625 count :  5
152
152 128
152 128
168 128
168 128
D:\원드라이브 백업\OneDrive\comm_marl2\comm_marl2\GDN3.py:404: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  agent_feature = torch.tensor(agent_feature, dtype=torch.float, device=device).unsqueeze(0)
D:\원드라이브 백업\OneDrive\comm_marl2\comm_marl2\GLCN\GLCN2.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(A[b], dtype=torch.long).to(device),
D:\원드라이브 백업\OneDrive\comm_marl2\comm_marl2\GLCN\GLCN2.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.ones(torch.tensor(A[b]).shape[1]).to(device),
MMM2 Total reward in episode 0 = 1.173, epsilon : 0.999, time_step : 35, episode_duration : 1.789, gamma2 : 0.01
upper_bound nan
MMM2 Total reward in episode 1 = 1.859, epsilon : 0.999, time_step : 71, episode_duration : 0.651, gamma2 : 0.01
upper_bound nan
nan
C:\Users\sueng\anaconda3\envs\pyg\lib\site-packages\numpy\core\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\sueng\anaconda3\envs\pyg\lib\site-packages\numpy\core\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
C:\Users\sueng\anaconda3\envs\pyg\lib\site-packages\numpy\core\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
C:\Users\sueng\anaconda3\envs\pyg\lib\site-packages\numpy\core\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
D:\원드라이브 백업\OneDrive\comm_marl2\comm_marl2\GDN3.py:404: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  agent_feature = torch.tensor(agent_feature, dtype=torch.float, device=device).unsqueeze(0)
D:\원드라이브 백업\OneDrive\comm_marl2\comm_marl2\GLCN\GLCN2.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(A[b], dtype=torch.long).to(device),
D:\원드라이브 백업\OneDrive\comm_marl2\comm_marl2\GLCN\GLCN2.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.ones(torch.tensor(A[b]).shape[1]).to(device),
MMM2 Total reward in episode 2 = 1.993, epsilon : 0.998, time_step : 104, episode_duration : 0.461, gamma2 : 0.01
upper_bound nan
MMM2 Total reward in episode 3 = 1.783, epsilon : 0.997, time_step : 140, episode_duration : 0.531, gamma2 : 0.01
upper_bound nan
MMM2 Total reward in episode 4 = 2.231, epsilon : 0.997, time_step : 183, episode_duration : 0.595, gamma2 : 0.01
upper_bound nan
MMM2 Total reward in episode 5 = 1.15, epsilon : 0.996, time_step : 216, episode_duration : 0.463, gamma2 : 0.01
upper_bound nan
MMM2 Total reward in episode 6 = 1.966, epsilon : 0.995, time_step : 254, episode_duration : 0.523, gamma2 : 0.01
upper_bound nan
MMM2 Total reward in episode 7 = 1.514, epsilon : 0.994, time_step : 297, episode_duration : 0.57, gamma2 : 0.01
upper_bound nan
MMM2 Total reward in episode 8 = 1.926, epsilon : 0.994, time_step : 328, episode_duration : 0.449, gamma2 : 0.01
upper_bound nan
MMM2 Total reward in episode 9 = 1.735, epsilon : 0.993, time_step : 361, episode_duration : 0.485, gamma2 : 0.01
upper_bound nan
MMM2 Total reward in episode 10 = 1.853, epsilon : 0.992, time_step : 401, episode_duration : 2.836, gamma2 : 0.01
